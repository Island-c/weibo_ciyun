[TOC]

# 微博热点词云

## 前端

花里胡哨炫酷吊炸天。

仿西电教务处，当前页面悬浮框确认服务，然后跳转到指定服务。

## 后端

流程： 

数据处理（爬虫、分词） ->  生成词云 ->  情感分析 -> 实时词云

### 数据处理

#### 微博爬虫

1. 模拟代理头，请求微博热搜页面
2. 根据html标签获取热搜文本，加入list
3. 将list返回

注：微博热搜第三条是广告。

#### 分词

##### jieba分词java版

1. 遍历热搜list，对每一条文本执行jieba分词，返回由词语组成的list；
2. 遍历分词后的list，去掉其中词长小于2的词和停用词；
3. 将分词结果导出。

##### 停用词和最小词长



### 词云生成

##### java python混合编程问题

实现方式：

- python是一种脚本语言，也就是说可以在控制台用"python 文件名 参数1 参数2"的方式运行。

- 使用java的runtime运行时环境可以直接执行命令行语句。

- 可以将命令行的输出结果通过IO流导入到java中，再输出到java控制台。
- 问题： 1. 效率很低  2. python的包依赖机制。

#### java词云

丑 ， 也不快

#### python词云

只慢一点点，但是好看

### 情感分析

snowNLP ： *情感分析（现在训练数据主要是买卖东西时的评价，所以对其他的一些可能效果不是很好，待解决）* 

针对每一条热搜，使用snowNLP生成一个情感值。 

所有情感值求平均，得到平均情感倾向。

平均情感倾向值越接近1，说明当前社会风气越正能量，越接近0，说明当前负能量较重。

### 实时词云

综合上述所有。

实现了定时自动刷新词云的功能。



### 一个没有集成进去的功能：支持向量机情感分类

使用训练好的词向量替换热搜中的词语 -> 将一句话映射为空间中的一个点。

使用支持向量机进行分类。

没有集成的原因： 

1. 词向量太大，读取运行太慢。  
2. 需要一定数量的训练集。而热搜每次只有50条。 
3. 训练集需要人工标注 

### 网页访问量

>  您是第XX位访问的用户。

**该功能的实现解决了四大问题：**



问题一： 每个用户都要有一个独一无二的访问编号。

解决：在服务端创建一个全局变量（生命周期为从服务器启动到服务器关闭），每次访问主页就将这个变量+1返回。



问题二： 假设如下场景： A访问网站，获取到编号160。然后B访问，获取161。此时服务器的全局变量更新为161，然后A刷新页面，A的编号发生了变化，变成了162。

解决：除了服务器的全局变量外，再给每个用户的每次会话创建一个局部变量（生命周期为从用户使用访问服务器到用户退出访问）。每次用户访问时，将这个时间点的全局变量的值赋给局部变量，将此局部变量作为这次访问的访问编号。



问题三： 全局变量的生命周期到服务器关闭就结束了，当服务器重启时又从0开始计数。

解决：将全局变量写入本地文件，每次启动服务器先从本地文件读取该编号。



问题四：服务器意外关闭来不及保存全局变量

解决：每次全局变量更新都写入一次文件。


